{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "287335dc-b723-42ca-84d3-f1d4d501a9a9",
   "metadata": {},
   "source": [
    "### Computer Vision: Real-Time Face Detection Using OpenCV\n",
    "\n",
    "#### **Introduction**\n",
    "In this project, I demonstrate real-time **face detection** using **OpenCV’s Haar Cascade Classifier**.  \n",
    "The goal is to detect human faces through the webcam feed, live video, and highlight them with bounding boxes in real-time.\n",
    "\n",
    "Haar cascades are one of the earliest and most widely used classical computer vision methods for object detection.  \n",
    "They use features extracted from grayscale images and apply a cascade of classifiers trained to detect specific objects — in this case, human faces.\n",
    "\n",
    "#### **Objective**\n",
    "- Use a pre-trained Haar Cascade model for detecting faces.  \n",
    "- Capture frames from the webcam.  \n",
    "- Convert frames to grayscale (since Haar cascades work on grayscale images).  \n",
    "- Detect faces and draw rectangles around them.  \n",
    "- Display the live video feed with detected faces in real-time.\n",
    "\n",
    "#### **Explanation of the Code**\n",
    "1. **Importing Libraries**  \n",
    "   - `cv2`: OpenCV library for image processing and computer vision tasks.  \n",
    "   - `time`: Used for performance measurement if needed.  \n",
    "\n",
    "2. **Loading the Pre-trained Classifier**  \n",
    "   - The `haarcascade_frontalface_default.xml` file contains the trained Haar features for frontal face detection.  \n",
    "\n",
    "3. **Accessing Webcam**  \n",
    "   - `cv2.VideoCapture(0)` opens the default webcam.  \n",
    "\n",
    "4. **Processing Each Frame**  \n",
    "   - The loop captures video frames continuously.  \n",
    "   - Each frame is converted to grayscale using `cv2.cvtColor()` to simplify computations.  \n",
    "\n",
    "5. **Face Detection**  \n",
    "   - `detectMultiScale()` scans the grayscale image to locate faces.  \n",
    "   - Parameters:  \n",
    "     - `scaleFactor=1.3`: Determines how much the image size is reduced at each image scale.  \n",
    "     - `minNeighbors=5`: Specifies how many neighbors each rectangle should have to retain it (reduces false positives).  \n",
    "\n",
    "6. **Drawing Rectangles**  \n",
    "   - Detected faces are highlighted using green rectangles.  \n",
    "\n",
    "7. **Displaying the Output**  \n",
    "   - The video window titled *\"Face Detection\"* shows real-time detection results.  \n",
    "   - Press **`q`** to exit the webcam stream safely.  \n",
    "\n",
    "8. **Releasing Resources**  \n",
    "   - Once exited, the webcam is released and all OpenCV windows are closed using `cv2.destroyAllWindows()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d28942a2-b910-4037-a5ce-6df1bdf6232c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import openCV and time libraries\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "# Load the pre-trained Haar cascade for face detection\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "# Open webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert to grayscale for detection\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=5)\n",
    "\n",
    "    # Draw rectangles around detected faces\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "    # Show the output\n",
    "    cv2.imshow(\"Face Detection\", frame)\n",
    "\n",
    "    # Quit on pressing 'q'\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Cleanup\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f354b1b-c81d-402f-8a56-113fdb6fe839",
   "metadata": {},
   "source": [
    "## Face Detection in Video with FPS and Face Count\n",
    "\n",
    "In this section, we extend the face detection system to work with a pre-recorded video instead of the webcam.  \n",
    "We also calculate and display the **Frames Per Second (FPS)** and the **number of detected faces** in each frame to monitor the performance of the face detection pipeline.\n",
    "\n",
    "###  How It Works\n",
    "1. **Load the Haar Cascade Classifier**  \n",
    "   We use the same pre-trained model `haarcascade_frontalface_default.xml` from OpenCV to detect frontal human faces.\n",
    "\n",
    "2. **Read Video Frames**  \n",
    "   The `cv2.VideoCapture()` function is used to open a video file. Each frame is processed sequentially.\n",
    "\n",
    "3. **Convert Frames to Grayscale**  \n",
    "   Since Haar cascades work best on grayscale images, each frame is converted using `cv2.cvtColor()`.\n",
    "\n",
    "4. **Detect Faces**  \n",
    "   The method `detectMultiScale()` identifies faces within the frame.  \n",
    "   Parameters:\n",
    "   - `scaleFactor=1.3` — reduces image size to detect smaller faces  \n",
    "   - `minNeighbors=5` — higher values reduce false positives\n",
    "\n",
    "5. **Draw Bounding Boxes & Display Info**  \n",
    "   Each detected face is highlighted with a green rectangle.  \n",
    "   On the top-left corner, we overlay:\n",
    "   - **FPS (Frames per Second)** — showing how fast the model processes video  \n",
    "   - **Face Count** — showing the number of faces detected per frame\n",
    "\n",
    "6. **Exit Mechanism**  \n",
    "   Press **‘q’** on the keyboard to stop the video display and close all OpenCV windows.\n",
    "\n",
    "###  Key Notes\n",
    "- **Haar Cascade Classifier**: A lightweight, pre-trained object detection algorithm included in OpenCV.  \n",
    "- **FPS Calculation**: Measures the time taken between frames to estimate how efficiently frames are processed.  \n",
    "- **Real-Time Detection**: Even though the input is a video file, the same approach applies to live streaming sources.\n",
    "\n",
    "This example demonstrates how computer vision can be applied to analyze video content, track multiple faces, and evaluate performance in real time.\n",
    "\n",
    "Video used is credited to original uploader. It is used for the education purpose only. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b79666c-1fa2-42fd-b99d-07715e0832f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing complete. Video playback finished.\n"
     ]
    }
   ],
   "source": [
    "#import openCV and time libraries\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "# Configuration \n",
    "video_path = \"video.mp4\"      \n",
    "resize_scale = 0.5           # Can resize scale for speed (0.5 = 50% smaller)\n",
    "\n",
    "# Load the pre-trained Haar cascade \n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "# Read the video\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video file.\")\n",
    "    exit()\n",
    "\n",
    "# Start processing frames\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"End of video\")\n",
    "        break\n",
    "\n",
    "    # Resize for faster processing\n",
    "    frame = cv2.resize(frame, None, fx=resize_scale, fy=resize_scale)\n",
    "\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Measure processing time for FPS\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Detect faces\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=5)\n",
    "\n",
    "    # Draw rectangles around faces\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "    # Calculate FPS\n",
    "    fps = 1.0 / (time.time() - start_time + 1e-6)\n",
    "\n",
    "    # Overlay text info\n",
    "    cv2.putText(frame, f\"Faces: {len(faces)}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2)\n",
    "    cv2.putText(frame, f\"FPS: {int(fps)}\", (10, 65), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255,0,0), 2)\n",
    "\n",
    "    # Display result\n",
    "    cv2.imshow(\"Face Detection on Video\", frame)\n",
    "\n",
    "    # Press 'q' to quit\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Cleanup\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(\"Processing complete. Video playback finished.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
